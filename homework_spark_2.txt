from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Practice").getOrCreate()

from pyspark import SparkFiles

covid_data_file_url = "https://raw.githubusercontent.com/glincow/netology-spark-sql/main/data/covid-data.csv"
spark.sparkContext.addFile(covid_data_file_url)
file_path  = 'file://' + SparkFiles.get('covid-data.csv')
df = spark.read.option('inferSchema', 'true').option('header', 'true').csv(file_path)

from pyspark.sql import functions as F
from pyspark.sql.window import Window

#1

df_15_countries=df.filter(F.col("date")=="2021-03-31").filter(F.col("population").isNotNull() & F.col("total_cases").isNotNull()).withColumn("percent_infected", (F.col("total_cases")/F.col("population"))*100).select("iso_code", "location", "percent_infected").orderBy(F.col("percent_infected").desc()).limit(15).show()

+--------+-------------+------------------+                                     
|iso_code|     location|  percent_infected|
+--------+-------------+------------------+
|     AND|      Andorra|15.543907331909661|
|     MNE|   Montenegro|14.523725364693293|
|     CZE|      Czechia|14.308848404077997|
|     SMR|   San Marino|13.937179562732041|
|     SVN|     Slovenia|10.370805779121204|
|     LUX|   Luxembourg| 9.847342390123583|
|     ISR|       Israel| 9.625106044786802|
|     USA|United States| 9.203010995860707|
|     SRB|       Serbia| 8.826328557933492|
|     BHR|      Bahrain| 8.488860079114566|
|     PAN|       Panama| 8.228739065460761|
|     PRT|     Portugal| 8.058699735120369|
|     EST|      Estonia| 8.022681579659551|
|     SWE|       Sweden| 7.969744347858805|
|     LTU|    Lithuania| 7.938864728274825|
+--------+-------------+------------------+

#2

df_top10_new_cases=df.filter((F.col("date")>="2021-03-25") & (F.col("date")<="2021-03-31")).groupBy("location").agg(F.max("new_cases").alias("max_new_cases"), F.first("iso_code").alias("iso_code")).select("iso_code", "location", "max_new_cases").orderBy(F.col("max_new_cases").desc()).limit(10).show()

+--------+--------------+-------------+                                         
|iso_code|      location|max_new_cases|
+--------+--------------+-------------+
|OWID_WRL|         World|     683205.0|
|OWID_EUR|        Europe|     255985.0|
|OWID_EUN|European Union|     216452.0|
|OWID_ASI|          Asia|     183350.0|
|OWID_SAM| South America|     148476.0|
|     BRA|        Brazil|     100158.0|
|OWID_NAM| North America|      93350.0|
|     USA| United States|      77321.0|
|     IND|         India|      72330.0|
|     FRA|        France|      59054.0|
+--------+--------------+-------------+

#3

df_russia=df.filter((F.col("location")=="Russia") & (F.col("date")>="2021-03-25") & (F.col("date")<="2021-03-31"))

window_spec=Window.partitionBy("location").orderBy("date")

df_russia_cases_change=df_russia.withColumn("previous_day_cases", F.lag("new_cases").over(window_spec)).withColumn("delta", F.col("new_cases")-F.col("previous_day_cases")).select("date", "previous_day_cases", "new_cases", "delta").orderBy("date").show()

+----------+------------------+---------+------+
|      date|previous_day_cases|new_cases| delta|
+----------+------------------+---------+------+
|2021-03-25|              NULL|   9128.0|  NULL|
|2021-03-26|            9128.0|   9073.0| -55.0|
|2021-03-27|            9073.0|   8783.0|-290.0|
|2021-03-28|            8783.0|   8979.0| 196.0|
|2021-03-29|            8979.0|   8589.0|-390.0|
|2021-03-30|            8589.0|   8162.0|-427.0|
|2021-03-31|            8162.0|   8156.0|  -6.0|
+----------+------------------+---------+------+